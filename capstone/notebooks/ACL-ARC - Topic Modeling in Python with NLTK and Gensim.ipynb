{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "# Topic Modelling in Python with NLTK and Gensim\n",
    "# Susan Li\n",
    "# Mar 30, 2018\n",
    "\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/ben/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ben/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with ACL Anthology Reference Corpus version 20080325\n",
    "# Site: http://acl-arc.comp.nus.edu.sg/#t\n",
    "# File: http://acl-arc.comp.nus.edu.sg/aclArc-20080325.tgz\n",
    "\n",
    "# First test opening a single file in the ACL corpus\n",
    "# Appears that not all files are UTF-8 encoded\n",
    "# See http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d2/docs/README-20090501.txt\n",
    "# \"pdfbox converted versions of the pdf files in UTF-8 encoding where possible\"\n",
    "\n",
    "def print_topics(file_path):\n",
    "    import random\n",
    "    text_data = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            tokens = prepare_text_for_lda(line)\n",
    "            if random.random() > .99:\n",
    "#                 print(tokens)\n",
    "                text_data.append(tokens)\n",
    "    print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['commercial', 'government', 'application']]\n",
      "[['describe', 'separate', 'section', 'detection', 'extrac-'], ['availability', 'funding', 'permit', 'addition'], ['license', 'develop', 'community']]\n"
     ]
    }
   ],
   "source": [
    "fp1 = '../datasets/acl-arc/txt/pdfbox-0.72/X/X93/X93-1001.txt'\n",
    "fp2 = '../datasets/acl-arc/txt/pdfbox-0.72/X/X93/X93-1002.txt'\n",
    "\n",
    "# Output is extremely random and varies every run\n",
    "print_topics(fp1)\n",
    "print_topics(fp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topics to a single text_data list instead of printing them for every file\n",
    "def add_topics(file_path, text_data):\n",
    "    import random\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            tokens = prepare_text_for_lda(line)\n",
    "            if random.random() > .99:\n",
    "                text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "add_topics(fp1, text_data)\n",
    "add_topics(fp2, text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['irrelevant', 'document', 'system'],\n",
       " ['crystal@arpa.mil'],\n",
       " ['evaluation', 'complete', 'system', 'development']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA with Gensim\n",
    "\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('../artifacts/acl-corpus.pkl', 'wb'))\n",
    "dictionary.save('../artifacts/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.143*\"crystal@arpa.mil\" + 0.143*\"system\" + 0.143*\"complete\" + 0.143*\"development\"')\n",
      "(1, '0.273*\"system\" + 0.273*\"document\" + 0.273*\"irrelevant\" + 0.045*\"crystal@arpa.mil\"')\n",
      "(2, '0.143*\"crystal@arpa.mil\" + 0.143*\"system\" + 0.143*\"complete\" + 0.143*\"development\"')\n",
      "(3, '0.188*\"evaluation\" + 0.188*\"development\" + 0.188*\"complete\" + 0.187*\"crystal@arpa.mil\"')\n",
      "(4, '0.143*\"crystal@arpa.mil\" + 0.143*\"system\" + 0.143*\"complete\" + 0.143*\"development\"')\n"
     ]
    }
   ],
   "source": [
    "# This is basically producing 5 different permutations of the same keywords.\n",
    "# I think we need to back up and figure out why the tokenization step is producing so few topic keywords.\n",
    "# Shouldn't it be producing a bunch more lists of keywords, roughly one for each line?\n",
    "\n",
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/.virtualenvs/capstone/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1190450689816165035031130\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1190450689816165035031130_data = {\"mdsDat\": {\"x\": [-0.003510309774957664, 0.10881565782886778, -0.0035103652257046244, -0.09828489674612782, -0.0035100860820776376], \"y\": [-0.0, 0.0, 0.0, 0.0, 0.0], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [5.130631446838379, 33.25676345825195, 5.130641460418701, 51.35133743286133, 5.1306304931640625]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05862220749258995, 0.05862201750278473, 0.05869524925947189, 0.05862352252006531, 0.05862332880496979, 0.05862332135438919, 0.05864086374640465, 0.7254087328910828, 0.725408673286438, 0.7259653806686401, 0.12096745520830154, 0.12093045562505722, 0.12093010544776917, 0.12092982232570648, 0.058622464537620544, 0.058622196316719055, 0.05869467183947563, 0.058624010533094406, 0.05862370505928993, 0.058623649179935455, 0.05864057317376137, 0.7704635858535767, 0.7704625129699707, 0.7704610228538513, 0.7699551582336426, 0.7698859572410583, 0.12843933701515198, 0.12843911349773407, 0.05862262845039368, 0.05862236022949219, 0.058694079518318176, 0.0586237795650959, 0.05862375721335411, 0.05862349271774292, 0.05864029377698898], \"Term\": [\"irrelevant\", \"document\", \"crystal@arpa.mil\", \"complete\", \"development\", \"evaluation\", \"system\", \"irrelevant\", \"document\", \"crystal@arpa.mil\", \"complete\", \"development\", \"evaluation\", \"system\", \"document\", \"irrelevant\", \"system\", \"crystal@arpa.mil\", \"complete\", \"development\", \"evaluation\", \"irrelevant\", \"document\", \"crystal@arpa.mil\", \"complete\", \"development\", \"evaluation\", \"system\", \"evaluation\", \"development\", \"complete\", \"crystal@arpa.mil\", \"system\", \"document\", \"irrelevant\", \"document\", \"irrelevant\", \"crystal@arpa.mil\", \"complete\", \"development\", \"evaluation\", \"system\"], \"Total\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.029714822769165, 1.029714822769165, 1.0670067071914673, 1.0672627687454224, 1.0672634840011597, 1.0672638416290283, 1.6717729568481445, 1.029714822769165, 1.029714822769165, 1.6717729568481445, 1.0670067071914673, 1.0672627687454224, 1.0672634840011597, 1.0672638416290283, 1.029714822769165, 1.029714822769165, 1.0670067071914673, 1.0672627687454224, 1.0672634840011597, 1.0672638416290283, 1.6717729568481445, 1.0672638416290283, 1.0672634840011597, 1.0672627687454224, 1.0670067071914673, 1.6717729568481445, 1.029714822769165, 1.029714822769165, 1.029714822769165, 1.029714822769165, 1.0670067071914673, 1.0672627687454224, 1.0672634840011597, 1.0672638416290283, 1.6717729568481445], \"loglift\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.10400000214576721, 0.10400000214576721, 0.06970000267028809, 0.0681999996304512, 0.0681999996304512, 0.0681999996304512, -0.38029998540878296, 0.7505999803543091, 0.7505999803543091, 0.2667999863624573, -1.076200008392334, -1.07669997215271, -1.07669997215271, -1.07669997215271, 0.10400000214576721, 0.10400000214576721, 0.06970000267028809, 0.0681999996304512, 0.0681999996304512, 0.0681999996304512, -0.38029998540878296, 0.34060001373291016, 0.34060001373291016, 0.34060001373291016, 0.3402000069618225, -0.10890000313520432, -1.4150999784469604, -1.4150999784469604, 0.10400000214576721, 0.10400000214576721, 0.06970000267028809, 0.0681999996304512, 0.0681999996304512, 0.0681999996304512, -0.38029998540878296], \"logprob\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.9460999965667725, -1.9460999965667725, -1.9449000358581543, -1.9460999965667725, -1.9460999965667725, -1.9460999965667725, -1.9457999467849731, -1.2994999885559082, -1.2994999885559082, -1.298799991607666, -3.0908000469207764, -3.091099977493286, -3.091099977493286, -3.091099977493286, -1.9460999965667725, -1.9460999965667725, -1.9449000358581543, -1.9460999965667725, -1.9460999965667725, -1.9460999965667725, -1.9457999467849731, -1.673699975013733, -1.673699975013733, -1.673699975013733, -1.674399971961975, -1.6744999885559082, -3.4653000831604004, -3.4653000831604004, -1.9460999965667725, -1.9460999965667725, -1.9449000358581543, -1.9460999965667725, -1.9460999965667725, -1.9460999965667725, -1.9457999467849731]}, \"token.table\": {\"Topic\": [4, 4, 4, 2, 4, 2, 2, 4], \"Freq\": [0.9369763731956482, 0.937201201915741, 0.9369757175445557, 0.9711426496505737, 0.9369754195213318, 0.9711426496505737, 0.598167359828949, 0.598167359828949], \"Term\": [\"complete\", \"crystal@arpa.mil\", \"development\", \"document\", \"evaluation\", \"irrelevant\", \"system\", \"system\"]}, \"R\": 7, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1190450689816165035031130\", ldavis_el1190450689816165035031130_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1190450689816165035031130\", ldavis_el1190450689816165035031130_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1190450689816165035031130\", ldavis_el1190450689816165035031130_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyLDAvis\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load('../artifacts/dictionary.gensim')\n",
    "corpus = pickle.load(open('../artifacts/acl-corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model5.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
